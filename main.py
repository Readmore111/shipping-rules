import os
import time
from datetime import datetime, timedelta
import pandas as pd
import requests
from playwright.sync_api import sync_playwright

# ================= é…ç½®åŒºåŸŸ (å˜é‡æ¥è‡ª GitHub Secrets) =================
FEISHU_APP_ID = os.environ.get("FEISHU_APP_ID")
FEISHU_APP_SECRET = os.environ.get("FEISHU_APP_SECRET")
DATA_TABLE_ID = os.environ.get("DATA_TABLE_ID")  # ä¸»æ•°æ®è¡¨ID
LOG_TABLE_ID = os.environ.get("LOG_TABLE_ID")    # æ—¥å¿—è¡¨ID
APP_TOKEN = os.environ.get("APP_TOKEN")          # å¤šç»´è¡¨æ ¼App Token
WEB_USER = os.environ.get("WEB_USER")            # ç½‘ç«™è´¦å·
WEB_PASS = os.environ.get("WEB_PASS")            # ç½‘ç«™å¯†ç 

# ================= é£ä¹¦ API å·¥å…·ç±» =================
class FeishuBot:
    def __init__(self):
        self.token = self.get_tenant_access_token()
    
    def get_tenant_access_token(self):
        """è·å–é£ä¹¦ Tenant Access Token"""
        url = "https://open.feishu.cn/open-apis/auth/v3/tenant_access_token/internal"
        try:
            resp = requests.post(url, json={"app_id": FEISHU_APP_ID, "app_secret": FEISHU_APP_SECRET})
            resp.raise_for_status()
            return resp.json().get("tenant_access_token")
        except Exception as e:
            print(f"âŒ è·å–é£ä¹¦Tokenå¤±è´¥: {e}")
            raise

    def add_records(self, table_id, records):
        """æ‰¹é‡å†™å…¥æ•°æ®åˆ°å¤šç»´è¡¨æ ¼"""
        url = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{table_id}/records/batch_create"
        headers = {"Authorization": f"Bearer {self.token}", "Content-Type": "application/json"}
        
        batch_size = 100
        total_added = 0
        
        for i in range(0, len(records), batch_size):
            batch = records[i:i+batch_size]
            payload = {"records": [{"fields": r} for r in batch]}
            try:
                resp = requests.post(url, headers=headers, json=payload)
                resp_json = resp.json()
                code = resp_json.get("code")
                
                if code == 0:
                    total_added += len(batch)
                else:
                    msg = resp_json.get("msg", "")
                    print(f"âš ï¸ å†™å…¥å¤±è´¥ (Batch {i}): Code {code} - {msg}")
                    if code == 1254045:
                        print("ğŸ‘‰ åŸå› åˆ†æï¼šã€åˆ—åä¸åŒ¹é…ã€‘ã€‚è¯·æ£€æŸ¥é£ä¹¦è¡¨æ ¼é‡Œæ˜¯å¦ç¼ºäº†æŸä¸ªåˆ—ï¼Œæˆ–è€…åˆ—åå†™é”™äº†ã€‚")
                    elif code == 1254302:
                        print("ğŸ‘‰ åŸå› åˆ†æï¼šã€æƒé™æ‹’ç»ã€‘ã€‚å¯èƒ½æ˜¯è¯•å›¾å†™å…¥'ç³»ç»Ÿå­—æ®µ'ï¼Œæˆ–è€…åº”ç”¨æ²¡å‘å¸ƒç‰ˆæœ¬ã€‚")
                    
                    if table_id == LOG_TABLE_ID:
                        raise Exception(f"é£ä¹¦è¿”å›é”™è¯¯: {resp_json}")
            except Exception as e:
                print(f"âŒ å†™å…¥è¯·æ±‚é”™è¯¯: {e}")
                if table_id == LOG_TABLE_ID:
                    raise e
        return total_added

    def delete_oldest_day(self, table_id, date_field_name="ä¸‹å•æ—¶é—´"):
        """æŸ¥æ‰¾å¹¶åˆ é™¤æœ€æ—©ä¸€å¤©(æ•´å¤©)çš„æ‰€æœ‰æ•°æ®"""
        print("ğŸ” æ­£åœ¨æ£€æŸ¥æ˜¯å¦æœ‰æ—§æ•°æ®éœ€è¦æ¸…ç†...")
        
        # 1. æŸ¥æ‰¾æœ€æ—©çš„ä¸€æ¡è®°å½•ï¼Œç¡®å®š"æœ€æ—©æ—¥æœŸ"
        url_list = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{table_id}/records"
        headers = {"Authorization": f"Bearer {self.token}"}
        # åªå–ä¸€æ¡ï¼Œç”¨æ¥å®šé”šç‚¹
        params_sort = {"sort": f'["{date_field_name} ASC"]', "page_size": 1}
        
        try:
            resp = requests.get(url_list, headers=headers, params=params_sort)
            data = resp.json().get("data", {}).get("items", [])
        except Exception as e:
            print(f"âš ï¸ æ— æ³•è·å–æ—§æ•°æ®(å¯èƒ½åˆ—åä¸å¯¹): {e}")
            return "è·å–å¤±è´¥", 0
        
        if not data:
            print("âœ… è¡¨æ ¼æ˜¯ç©ºçš„ï¼Œæ— éœ€åˆ é™¤ã€‚")
            return "æ— æ•°æ®", 0

        # è·å–æœ€æ—©çš„æ—¶é—´æˆ³
        oldest_ts = data[0]["fields"].get(date_field_name)
        if not isinstance(oldest_ts, (int, float)):
             print(f"âš ï¸ æœ€æ—©çš„ä¸€æ¡æ•°æ®æ—¥æœŸæ ¼å¼ä¸å¯¹({oldest_ts})ï¼Œè·³è¿‡åˆ é™¤ã€‚")
             return "æ ¼å¼é”™è¯¯", 0

        # è®¡ç®—å½“å¤©çš„ 00:00:00 å’Œ 23:59:59 æ—¶é—´æˆ³
        dt = datetime.fromtimestamp(oldest_ts / 1000)
        day_start = dt.replace(hour=0, minute=0, second=0, microsecond=0)
        day_end = dt.replace(hour=23, minute=59, second=59, microsecond=999999)
        
        ts_start = int(day_start.timestamp() * 1000)
        ts_end = int(day_end.timestamp() * 1000)
        
        date_str = day_start.strftime("%Y-%m-%d")
        print(f"ğŸ—‘ï¸ é”å®šæœ€æ—©æ—¥æœŸ: {date_str}ï¼Œæ­£åœ¨æœç´¢è¯¥å¤©æ‰€æœ‰æ•°æ®...")

        # 2. ä½¿ç”¨ filter æœç´¢è¯¥æ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰æ•°æ®
        # è¯­æ³•: AND(CurrentValue.[ä¸‹å•æ—¶é—´]>=ts_start, CurrentValue.[ä¸‹å•æ—¶é—´]<=ts_end)
        filter_str = f'AND(CurrentValue.[{date_field_name}]>={ts_start},CurrentValue.[{date_field_name}]<={ts_end})'
        
        # è®¾ç½® page_size ä¸º 500 (é£ä¹¦å•æ¬¡æŸ¥è¯¢ä¸Šé™)ï¼Œå¦‚æœä¸æ­¢500æ¡å¯èƒ½éœ€è¦å¾ªç¯ï¼Œä½†å¯¹äºä¸€å¤©çš„æ•°æ®é€šå¸¸å¤Ÿäº†
        params_filter = {"filter": filter_str, "page_size": 500}
        
        resp_filter = requests.get(url_list, headers=headers, params=params_filter)
        items_to_delete = resp_filter.json().get("data", {}).get("items", [])
        
        if not items_to_delete:
            return f"{date_str} (æœªæ‰¾åˆ°)", 0

        # 3. æ‰¹é‡åˆ é™¤
        record_ids = [item["record_id"] for item in items_to_delete]
        print(f"ğŸ‘‹ æ‰¾åˆ° {len(record_ids)} æ¡æ•°æ®å±äº {date_str}ï¼Œå‡†å¤‡å…¨éƒ¨åˆ é™¤...")
        
        total_deleted = 0
        batch_size = 100
        url_del = f"https://open.feishu.cn/open-apis/bitable/v1/apps/{APP_TOKEN}/tables/{table_id}/records/batch_delete"
        
        # åˆ†æ‰¹åˆ é™¤ (æ¯æ¬¡100æ¡)
        for i in range(0, len(record_ids), batch_size):
            batch_ids = record_ids[i:i+batch_size]
            resp_del = requests.post(url_del, headers=headers, json={"records": batch_ids})
            if resp_del.json().get("code") == 0:
                total_deleted += len(batch_ids)
            else:
                print(f"âš ï¸ åˆ é™¤å¤±è´¥: {resp_del.json()}")

        print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {date_str} çš„ {total_deleted} æ¡è®°å½•ã€‚")
        return date_str, total_deleted

    def log_result(self, status, added, deleted_info, deleted_count, error=""):
        """å°†è¿è¡Œç»“æœå†™å…¥æ—¥å¿—è¡¨"""
        if deleted_info is None:
            deleted_info = "æ— "
            
        fields = {
            "æ‰§è¡ŒçŠ¶æ€": status,
            "æ–°å¢æ¡æ•°": added,
            "åˆ é™¤æ—¥æœŸ": str(deleted_info),
            "åˆ é™¤æ¡æ•°": deleted_count,
            "é”™è¯¯è¯¦æƒ…": str(error)
        }
        try:
            print(f"ğŸ“‹ å‡†å¤‡å†™å…¥æ—¥å¿—: {fields}")
            self.add_records(LOG_TABLE_ID, [fields])
            print("âœ… æ—¥å¿—å·²è®°å½•")
        except Exception as e:
            print(f"âŒ æ—¥å¿—å†™å…¥å¤±è´¥! åŸå› : {e}")

# ================= æµè§ˆå™¨è‡ªåŠ¨åŒ– =================
def download_excel_from_web():
    """ä½¿ç”¨ Playwright æ¨¡æ‹Ÿä¸‹è½½"""
    # è®¾å®šæ—¶é—´é€»è¾‘ï¼šè·å–æ˜¨å¤©çš„æ•°æ®
    yesterday = datetime.now() - timedelta(days=1)
    start_str = yesterday.strftime("%Y-%m-%d 00:00:00")
    end_str = yesterday.strftime("%Y-%m-%d 23:59:59")
    
    print(f"ğŸ“… å‡†å¤‡ä¸‹è½½æ•°æ®åŒºé—´: {start_str} åˆ° {end_str}")

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--safebrowsing-disable-download-protection", "--allow-running-insecure-content", "--disable-web-security"]
        )
        context = browser.new_context(accept_downloads=True)
        page = context.new_page()
        
        try:
            print("ğŸ”„ æ­£åœ¨æ‰“å¼€ç½‘é¡µ...")
            page.goto("http://111.230.72.108:8082/orderQuery.htm")
            print("ğŸ”‘ æ­£åœ¨ç™»å½•...")
            page.fill('#username', WEB_USER)       
            page.fill('#inputPassword', WEB_PASS)  
            page.click('input[value="ç™» å½•"]')
            
            print("â³ ç­‰å¾…é¡µé¢è·³è½¬...")
            menu_selector = 'text=å…¨éƒ¨è®¢å•/å¯¼å‡º >> visible=true'
            page.wait_for_selector(menu_selector, timeout=60000)
            print("ğŸ“‚ è¿›å…¥å¯¼å‡ºé¡µé¢...")
            page.click(menu_selector) 
            
            print("â³ ç­‰å¾…æ—¥æœŸè¾“å…¥æ¡†åŠ è½½...")
            page.wait_for_selector('#sTime', state='attached', timeout=30000)
            
            print("ğŸ“… æ­£åœ¨è®¾ç½®æ—¥æœŸ...")
            js_script = f"""
                document.getElementById('sTime').removeAttribute('readonly');
                document.getElementById('sTime').value = '{start_str}';
                document.getElementById('eTime').removeAttribute('readonly');
                document.getElementById('eTime').value = '{end_str}';
            """
            page.evaluate(js_script)
            
            print("â¬‡ï¸ ç‚¹å‡»ä¸‹è½½...")
            with page.expect_download() as download_info:
                page.click('button:has-text("ä¸‹è½½")')
            
            download = download_info.value
            save_path = os.path.join(os.getcwd(), "result.xls")
            download.save_as(save_path)
            
            browser.close()
            print(f"âœ… ä¸‹è½½å®Œæˆ: {save_path}")
            return save_path
            
        except Exception as e:
            browser.close()
            raise e

# ================= ä¸»æµç¨‹ =================
if __name__ == "__main__":
    bot = FeishuBot()
    try:
        print("ğŸš€ ä»»åŠ¡å¼€å§‹...")
        
        file_path = download_excel_from_web()
        
        print("ğŸ“– æ­£åœ¨è§£æ Excel...")
        df = pd.read_excel(file_path, header=0, engine='xlrd') 
        df.dropna(how='all', inplace=True)

        print("ğŸ”§ æ­£åœ¨é‡å‘½åå†²çªå­—æ®µ...")
        df.rename(columns={'åˆ›å»ºæ—¶é—´': 'ä¸‹å•æ—¶é—´'}, inplace=True)

        date_columns = ["ä¸‹å•æ—¶é—´", "å‡ºè´§æ—¶é—´", "æ‰“å°æ—¶é—´"]
        
        print(f"â³ æ­£åœ¨å¼ºåˆ¶è½¬æ¢æ—¥æœŸåˆ—: {date_columns} ...")
        for col in date_columns:
            if col in df.columns:
                df[col] = pd.to_datetime(df[col], errors='coerce')

        records = df.to_dict(orient="records")
        print(f"ğŸ“Š è§£æåˆ° {len(records)} æ¡æ•°æ®")

        for r in records:
            for k, v in r.items():
                if pd.isna(v):
                    r[k] = None
                    continue
                if isinstance(v, (pd.Timestamp, datetime)):
                    try:
                        r[k] = int(v.timestamp() * 1000)
                    except:
                        r[k] = None

        # 3. å†™å…¥é£ä¹¦
        added_count = 0
        if records:
            print("â˜ï¸ æ­£åœ¨ä¸Šä¼ åˆ°é£ä¹¦...")
            added_count = bot.add_records(DATA_TABLE_ID, records)
        else:
            print("âš ï¸ æ²¡ä¸‹è½½åˆ°æ•°æ®ï¼Œè·³è¿‡ä¸Šä¼ ")
        
        # 4. æ¸…ç†æ—§æ•°æ® (è¿™é‡Œå·²é‡æ–°å¼€å¯)
        print("ğŸ—‘ï¸ å‡†å¤‡æ‰§è¡Œæ—§æ•°æ®æ¸…ç†...")
        # å³ä½¿æ²¡ä¸Šä¼ æ–°æ•°æ®ï¼Œä¹Ÿä¼šæ£€æŸ¥å¹¶æ¸…ç†æœ€è€çš„ä¸€å¤©ï¼Œä¿æŒæ•°æ®é‡å¹³è¡¡
        del_info, del_count = bot.delete_oldest_day(DATA_TABLE_ID, date_field_name="ä¸‹å•æ—¶é—´")
        
        # 5. è®°å½•æˆåŠŸæ—¥å¿—
        bot.log_result("æˆåŠŸ", added_count, del_info, del_count)
        print("ğŸ‰ ä»»åŠ¡å…¨éƒ¨å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä»»åŠ¡å‡ºé”™: {e}")
        bot.log_result("å¤±è´¥", 0, "æ— ", 0, str(e))
        raise e
